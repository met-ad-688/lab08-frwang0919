{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Module 05: Lab 02\"\n",
        "subtitle: \"Regression Modeling on Employment Data\"\n",
        "author:\n",
        "  - name: Furong Wang\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: \"2025-04-07\"\n",
        "format:\n",
        "  html:\n",
        "    theme: cerulean\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "date-modified: today\n",
        "date-format: long\n",
        "execute: \n",
        "  echo: false\n",
        "  eval: false\n",
        "  freeze: auto\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Objectives {.unnumbered}\n",
        "\n",
        "1. Use **PySpark** to process the Lightcast dataset.\n",
        "2. Engineer features from structured columns for salary prediction.\n",
        "3. Train **Linear Regression model**.\n",
        "4. Evaluate models using **RMSE** and **R²**.\n",
        "5. Visualize predictions using diagnostic plots.\n",
        "6. Push work to GitHub and submit the repository link.\n",
        "\n",
        "# Setup {.unnumbered}\n",
        "\n",
        "The instruction below provides you with general keywords for columns used in the lightcast file. See the data schema generated after the load dataset code above to use proper column name. For visualizations, tables, or summaries, please **customize colors, fonts, and styles** as appropriate to avoid a **2.5-point deduction**. Also, **provide a two-sentence explanation** describing key insights drawn from each section's code and outputs. \n",
        "\n",
        "1. Follow the steps below as necessary, use your best judgement in importing/installing/creating/saving files as needed.\n",
        "2. Create a new Jupyter Notebook in your `ad688-sp25-lab08` directory named `lab08_yourname.ipynb`, if the file exists make sure to change the name.\n",
        "3. Use your **EC2 instance** for this lab.\n",
        "4. Ensure the `lightcast_data.csv` file is available on the EC2 instance. if not then **Download the dataset**\n",
        "5. **Add the dataset to `.gitignore`** to avoid pushing large files to GitHub. Open your `.gitignore` file and add:\n",
        "6. Make sure to create a virtual environment and install the required Python libraries if needed, don't forget to activate it:\n",
        "7. Install the required Python libraries if needed, you can also use the given requirement file to install the packages to the virtual environment:\n",
        "\n",
        "```bash\n",
        "python3 -m venv .venv\n",
        "source .venv/bin/activate\n",
        "gdown https://drive.google.com/uc?id=1V2GCHGt2dkFGqVBeoUFckU4IhUgk4ocQ\n",
        "echo \"lightcast_job_postings.csv\" >> .gitignore\n",
        "pip install -r requirements.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Load the Dataset\n",
        "1. **Load the Raw Dataset**:\n",
        "   - Use Pyspark to the `lightcast_data.csv` file into a DataFrame:\n",
        "   - You can reuse the previous code. \n",
        "   - [Copying code from your friend constitutes plagiarism. DO NOT DO THIS]{.uured-bold}."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"notebook\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "\n",
        "# df.printSchema()\n",
        "# df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering\n",
        "\n",
        "Feature Engineering is a crucial step in preparing your data for machine learning. In this lab, we will focus on the following tasks:\n",
        "\n",
        "1. **Drop rows with missing values** in the target variable and key features.\n",
        "2. By now you are already familiar with the code and the data. Based on your understanding please choose any 3 (my code output has 10) variables as:\n",
        "   1. two continuous variables (use your best judgment!)\n",
        "   2. one categorical.\n",
        "   3. Your dependent variable (y) is `SALARY`.\n",
        "3. **Convert categorical variables** into numerical representations using **StringIndexer** and **OneHotEncoder**.\n",
        "4. **Assemble features** into a single vector using **VectorAssembler**.\n",
        "5. **Split the data** into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------------------+\n",
            "|SALARY|features           |\n",
            "+------+-------------------+\n",
            "|192800|[55.0,6.0,1.0,0.0] |\n",
            "|125900|[18.0,12.0,1.0,0.0]|\n",
            "|118560|[20.0,5.0,1.0,0.0] |\n",
            "|192800|[55.0,6.0,1.0,0.0] |\n",
            "|116500|[16.0,12.0,1.0,0.0]|\n",
            "+------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#| eval: false\n",
        "#| echo: true\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "df = df.dropna(subset=['MODELED_DURATION', 'MIN_YEARS_EXPERIENCE', 'EMPLOYMENT_TYPE_NAME', 'SALARY'])\n",
        "\n",
        "categorical_col = ['EMPLOYMENT_TYPE_NAME']\n",
        "continuous_cols = ['MODELED_DURATION', 'MIN_YEARS_EXPERIENCE']\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid='skip') for col in categorical_col]\n",
        "encoders = [OneHotEncoder(inputCol=f\"{col}_idx\", outputCol=f\"{col}_vec\") for col in categorical_col]\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=continuous_cols + [f\"{col}_vec\" for col in categorical_col],\n",
        "    outputCol='features'\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "data = pipeline.fit(df).transform(df)\n",
        "data.select('SALARY', 'features').show(5, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train/Test Split\n",
        "\n",
        "- Perform a **random split** of the data into training and testing sets.\n",
        "- Set a random seed for reproducibility.\n",
        "- You can choose a number for splitting to your liking, justify your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9687, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 113:>                                                        (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2354, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#| eval: true\n",
        "#| echo: false\n",
        "data = data.select('SALARY', 'features')\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=688)\n",
        "print((train_data.count(), len(train_data.columns)))\n",
        "print((test_data.count(), len(test_data.columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear Regression\n",
        "\n",
        "- Train a **Linear Regression** model using the training data. [You will run in to an important issue here. Please make an effort in figuring it by yourself. This is one of the most asked interview questions in CapitalOne's management recruiting program.]{.uured-bold}\n",
        "- Evaluate the model on the test data.\n",
        "- Print the coefficients, intercept, R², RMSE, and MAE.\n",
        "- Use the `summary` object to extract the coefficients and their standard errors, t-values, and p-values.\n",
        "- Create a DataFrame to display the coefficients, standard errors, t-values, p-values, and confidence intervals.\n",
        "- Interpret the coefficients and their significance and explain the model performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "train_data = train_data.withColumn('SALARY', col('SALARY').cast(\"double\"))\n",
        "test_data = test_data.withColumn('SALARY', col('SALARY').cast(\"double\"))\n",
        "\n",
        "feature_names = assembler.getInputCols()\n",
        "\n",
        "lr = LinearRegression(featuresCol='features', labelCol='SALARY', regParam=0.1)\n",
        "lr_model = lr.fit(train_data)\n",
        "summary = lr_model.summary\n",
        "\n",
        "test_results = lr_model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intercept: 81557.0905\n",
            "Coefficients:\n",
            "  Feature 1: 5.2474\n",
            "  Feature 2: 6628.0128\n",
            "  Feature 3: 1568.7527\n",
            "  Feature 4: -1472.5974\n"
          ]
        }
      ],
      "source": [
        "# Coefficients and Intercept\n",
        "print(\"Intercept: {:.4f}\".format(lr_model.intercept))\n",
        "print(\"Coefficients:\")\n",
        "for i, coef in enumerate(lr_model.coefficients):\n",
        "     print(f\"  Feature {i + 1}: {coef:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R² on test data: 0.2875\n",
            "RMSE on test data: 34889.8251\n",
            "MAE on test data: 27223.0712\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation\n",
        "print(\"R² on test data: {:.4f}\".format(test_results.r2))\n",
        "print(\"RMSE on test data: {:.4f}\".format(test_results.rootMeanSquaredError))\n",
        "print(\"MAE on test data: {:.4f}\".format(test_results.meanAbsoluteError))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----------+---------------------+--------------------+---------------------+--------------------+---------------------+--------------------+\n",
            "|   |  Feature  |      Estimate       |     Std Error      |       t-stat        |      P-Value       |      CI Lower       |      CI Upper      |\n",
            "+---+-----------+---------------------+--------------------+---------------------+--------------------+---------------------+--------------------+\n",
            "| 0 | Intercept |  81557.09053491428  | 27.82825524390048  | 0.18856355648140694 | 0.8504388500837061 |  81502.54715463624  | 81611.63391519233  |\n",
            "| 1 | Feature_1 |  5.247394779462237  | 111.94747384912434 |  59.20645215080544  |        0.0         | -214.16965396482146 | 224.66444352374594 |\n",
            "| 2 | Feature_2 |  6628.012753851724  | 3023.391018286486  |  0.518871934594955  | 0.6038619092050608 |  702.1663580102113  | 12553.859149693235 |\n",
            "| 3 | Feature_3 | 1568.7527466953197  | 3796.141341594617  | -0.3879195510556373 | 0.6980840973560669 |  -5871.68428283013  |  9009.18977622077  |\n",
            "| 4 | Feature_4 | -1472.5974449751286 | 3053.393455814185  |  26.7103115648642   |        0.0         | -7457.248618370931  | 4512.053728420674  |\n",
            "+---+-----------+---------------------+--------------------+---------------------+--------------------+---------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# Print the coefficient table\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "coefs = [lr_model.intercept] + list(lr_model.coefficients)\n",
        "se = list(summary.coefficientStandardErrors)\n",
        "tvals = list(summary.tValues)\n",
        "pvals = list(summary.pValues)\n",
        "ci_low = [c - 1.96 * s for c, s in zip(coefs, se)]\n",
        "ci_high = [c + 1.96 * s for c, s in zip(coefs, se)]\n",
        "\n",
        "features = [\"Intercept\"] +  [f\"Feature_{i}\" for i in range(1, len(coefs))]\n",
        "\n",
        "# print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "# print(\"Length of features:\", len(features))\n",
        "# print(\"Length of coefs:\", len(coefs))\n",
        "# print(\"Length of se:\", len(se))\n",
        "# print(\"Length of tvals:\", len(tvals))\n",
        "# print(\"Length of pvals:\", len(pvals))\n",
        "\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Estimate\": coefs,\n",
        "    \"Std Error\": se,\n",
        "    \"t-stat\": tvals,\n",
        "    \"P-Value\": pvals,\n",
        "    \"CI Lower\": ci_low,\n",
        "    \"CI Upper\": ci_high})\n",
        "\n",
        "print(tabulate(coef_table, headers=\"keys\", tablefmt=\"pretty\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generalized Linear Regression Summary\n",
        "The summary of the Generalized Linear Regression model provides important insights into the model's performance and the significance of each feature. The coefficients indicate the relationship between each feature and the target variable (salary), while the standard errors, t-values, and p-values help assess the reliability of these estimates.\n",
        "\n",
        "- Please interpret them in the context of your data and model. \n",
        "- Feature Names are purposefully not printed in the output. You can use the `features` variable to print them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 119:>                                                        (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---------------------------------------------+---------------------+--------------------+---------------------+--------------------+\n",
            "|   |                   Feature                   |      Estimate       |     Std Error      |       t-stat        |      P-Value       |\n",
            "+---+---------------------------------------------+---------------------+--------------------+---------------------+--------------------+\n",
            "| 0 |                  Intercept                  |  81557.09053491428  | 27.82825524390048  | 0.18856355648140694 | 0.8504388500837061 |\n",
            "| 1 |              MODELED_DURATION               |  5.247394779462237  | 111.94747384912434 |  59.20645215080544  |        0.0         |\n",
            "| 2 |            MIN_YEARS_EXPERIENCE             |  6628.012753851724  | 3023.391018286486  |  0.518871934594955  | 0.6038619092050608 |\n",
            "| 3 | EMPLOYMENT_TYPE_NAME=Full-time (> 32 hours) | 1568.7527466953197  | 3796.141341594617  | -0.3879195510556373 | 0.6980840973560669 |\n",
            "| 4 | EMPLOYMENT_TYPE_NAME=Part-time (≤ 32 hours) | -1472.5974449751286 | 3053.393455814185  |  26.7103115648642   |        0.0         |\n",
            "+---+---------------------------------------------+---------------------+--------------------+---------------------+--------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#| eval: true\n",
        "#| echo: false\n",
        "\n",
        "pipeline_model = pipeline.fit(df)\n",
        "indexer_model = pipeline_model.stages[0]\n",
        "categories = indexer_model.labels\n",
        "\n",
        "encoded_categories = categories[:-1]\n",
        "encoded_feature_names = [f\"{categorical_col[0]}={cat}\" for cat in encoded_categories]\n",
        "feature_names = ['Intercept'] + continuous_cols + encoded_feature_names\n",
        "\n",
        "coef_table_2 = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Estimate\": coefs,\n",
        "    \"Std Error\": se,\n",
        "    \"t-stat\": tvals,\n",
        "    \"P-Value\": pvals\n",
        "})\n",
        "\n",
        "print(tabulate(coef_table_2, headers=\"keys\", tablefmt=\"pretty\"))\n",
        "coef_table_2.to_csv(\"_output/lr_summary_pretty.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diagnostic Plot\n",
        "\n",
        "Diagnostic plots are essential for evaluating the performance of regression models. In this section, we will create several diagnostic plots to assess the linear regression model's assumptions and performance. There are four (2*2 grid) main plots we will create, you can use `seaborn` or `matplotlib` for this:\n",
        "\n",
        "1. **Predicted vs Actual Plot**\n",
        "2. **Residuals vs Predicted Plot**\n",
        "3. **Histogram of Residuals**\n",
        "4. **QQ Plot of Residuals**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| eval: true\n",
        "#| echo: false\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Load predictions from GLR model\n",
        "df_pred = summary.predictions.select()\n",
        "\n",
        "# Compute residuals\n",
        "df_pred[\"residuals\"] = \n",
        "df_pred[\"fitted\"] = \n",
        "\n",
        "# Standardized residuals\n",
        "res_mean = \n",
        "res_std = \n",
        "df_pred[\"std_residuals\"] = \n",
        "\n",
        "# Square root of standardized residuals (for Scale-Location)\n",
        "df_pred[\"sqrt_std_resid\"] = \n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Plot 1: Residuals vs Fitted\n",
        "plt.subplot(2, 2, 1)\n",
        "\n",
        "\n",
        "# Plot 2: Normal Q-Q\n",
        "plt.subplot(2, 2, 2)\n",
        "\n",
        "\n",
        "# Plot 3: Scale-Location\n",
        "plt.subplot(2, 2, 3)\n",
        "\n",
        "\n",
        "# Plot 4: Residuals vs Leverage — Approximate\n",
        "# Note: Leverage & Cook's Distance require X matrix; we approximate using fitted & residual\n",
        "plt.subplot(2, 2, 4)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"_output/glr_diagnostic_classic.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation\n",
        "\n",
        "The evaluation of the model is crucial to understand its performance. In this section, we will calculate and visualize the following metrics:\n",
        "1. **R² (Coefficient of Determination)**: Indicates how well the model explains the variance in the target variable.\n",
        "2. **RMSE (Root Mean Squared Error)**: Measures the average magnitude of the errors between predicted and actual values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| eval: true\n",
        "#| echo: false\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.functions import col, pow, sqrt, avg\n",
        "import numpy as np\n",
        "\n",
        "pred_glr = lr_model.transform(test_data)\n",
        "\n",
        "# R²\n",
        "r2_eval = \n",
        "r2 = \n",
        "# AIC from GLR summary\n",
        "aic = \n",
        "\n",
        "# BIC calculation\n",
        "n = \n",
        "k = \n",
        "rss = \n",
        "bic = \n",
        "\n",
        "# RMSE manually\n",
        "residuals_df = \n",
        "rmse = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation Plot\n",
        "\n",
        "- Display the predicted vs actual salary plot with a red line indicating the ideal fit (y=x).\n",
        "- Use `seaborn` or `matplotlib` to create the plot.\n",
        "- Customize the plot with appropriate titles, labels, and legends.\n",
        "- Describe the plot in a few sentences, highlighting key insights and observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| eval: true\n",
        "#| echo: false\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert GLR predictions to pandas\n",
        "pandas_df = \n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "plt.title(f\"Predicted vs Actual Salary (GLR Model)\\n\"\n",
        "          f\"RMSE = {rmse:.2f} | R² = {r2:.4f} | AIC = {aic:.2f} | BIC = {bic:.2f}\", loc=\"left\", fontsize=14, fontweight=\"bold\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save figure\n",
        "plt.savefig(\"_output/glr_predicted_vs_actual.png\", dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Submission {.unnumbered}\n",
        "1. Save figures in the `_output/` folder.\n",
        "2. Commit and push code and output files:\n",
        "```bash\n",
        "git add .\n",
        "git commit -m \"Add Lab 08 Salary Prediction models and output\"\n",
        "git push origin main\n",
        "```\n",
        "3. Submit your GitHub repository link.\n",
        "\n",
        "# Resources {.unnumbered}\n",
        "- [PySpark MLlib Docs](https://spark.apache.org/docs/latest/ml-guide.html)  \n",
        "- [Seaborn Docs](https://seaborn.pydata.org/)  \n",
        "- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
